{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker Decomposition using ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorly as tl # Used for verification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode-N Matricization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) tensor: Input tensor\n",
    "        2) n: mode along which to matricize the tensor (mode is 0-indexed)\n",
    "Output: matrix: n-mode matricization of the tensor\n",
    "\"\"\"\n",
    "# Take mode = 0 for the first mode, mode = 1 for the second mode, ...., mode = n-1 for nth mode\n",
    "def mode_n_matricization(tensor, n):\n",
    "    mode = n\n",
    "    # Get the size of the original tensor\n",
    "    sz = tensor.size()\n",
    "    # print(f\"tensor size: {sz}\")\n",
    "\n",
    "    # Permute the dimensions of the tensor to bring the chosen mode to the front\n",
    "    # This will make it easy to reshape the tensor into a matrix along the chosen mode\n",
    "    permuted_dimensions = list(range(len(sz)))\n",
    "#     print('Before Permuation, dimensions: ', permuted_dimensions)\n",
    "    permuted_dimensions.remove(mode)\n",
    "    permuted_dimensions.insert(0, mode)\n",
    "#     print('After Permuation, dimensions: ', permuted_dimensions)\n",
    "    permuted_tensor = tensor.permute(*permuted_dimensions)\n",
    "#     print(f\"permuted tensor size: {permuted_tensor.size()}\")\n",
    "\n",
    "    # Reshape the permuted tensor into a matrix along the chosen mode\n",
    "    matrix = permuted_tensor.reshape(sz[mode], -1)\n",
    "#     print(f\"matrix size: {matrix.size()}\")\n",
    "\n",
    "#     print(f\"n-mode matricization along mode {mode}:\")\n",
    "#     print(matrix)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Mode-N Matricization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: torch.Size([2, 3, 4])\n",
      "\n",
      "n-mode matricization along mode 0:\n",
      "tensor([[ 1.,  4.,  7., 10.,  2.,  5.,  8., 11.,  3.,  6.,  9., 12.],\n",
      "        [13., 16., 19., 22., 14., 17., 20., 23., 15., 18., 21., 24.]])\n",
      "\n",
      "n-mode matricization along mode 1:\n",
      "tensor([[ 1.,  4.,  7., 10., 13., 16., 19., 22.],\n",
      "        [ 2.,  5.,  8., 11., 14., 17., 20., 23.],\n",
      "        [ 3.,  6.,  9., 12., 15., 18., 21., 24.]])\n",
      "\n",
      "n-mode matricization along mode 2:\n",
      "tensor([[ 1.,  2.,  3., 13., 14., 15.],\n",
      "        [ 4.,  5.,  6., 16., 17., 18.],\n",
      "        [ 7.,  8.,  9., 19., 20., 21.],\n",
      "        [10., 11., 12., 22., 23., 24.]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.empty((2,3,4))\n",
    "my_tensor[0, :, :] = torch.tensor([[1,4,7,10], [2,5,8,11], [3,6,9,12]])\n",
    "my_tensor[1, :, :] = torch.tensor([[13,16,19,22], [14,17,20,23], [15,18,21,24]])\n",
    "print(f\"Original Tensor: {my_tensor.size()}\")\n",
    "\n",
    "for n in range(len(my_tensor.size())):\n",
    "    print(f\"\\nn-mode matricization along mode {n}:\")\n",
    "    matrix = mode_n_matricization(my_tensor, n)\n",
    "    print(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher Order Singular Value Decomposition (HOSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) X: Input tensor of size (s_1,s_2,...,s_N)\n",
    "        2) R: array of decomposition ranks of size N (R_1,R_2,...,R_N)\n",
    "Output: A: array of factor matrices of size N (A_1,A_2,...,A_N)\n",
    "\"\"\"\n",
    "def HOSVD(X, R):\n",
    "    N = len(R)\n",
    "    A = []\n",
    "    for n in range(N):\n",
    "        # Matricize the input tensor along the n-th mode\n",
    "        Xn = mode_n_matricization(X, n)\n",
    "        # Compute the left singular matrix of the n-th matricization\n",
    "        U = torch.svd(Xn).U\n",
    "        # Take the leading R[n] columns of the left singular matrix\n",
    "        if(R[n] > U.size()[1]):\n",
    "            Zero = torch.zeros(U.size()[0], R[n] - U.size()[1])\n",
    "            An = torch.cat((U, Zero), dim=1)\n",
    "        else:\n",
    "            An = U[:, :R[n]]\n",
    "        A.append(An)\n",
    "    return A  \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einsum functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equation: abcde,za,yb,xc,wd,ve->zyxwv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Input: T: Input tensor\n",
    "Output: equation: equation string for torch.einsum()\n",
    "\"\"\"\n",
    "def einsum_equation(T):\n",
    "    equation = ''\n",
    "    for i in range(len(T.size())): \n",
    "        equation += f'{chr(97 + i)}'\n",
    "    for i in range(len(T.size())):\n",
    "        equation += f',{chr(122 -i)}{chr(97 + i)}'\n",
    "    equation += '->'\n",
    "    for i in range(len(T.size())):\n",
    "        equation += f'{chr(122 - i)}'\n",
    "    # print(f\"equation: {equation}\")\n",
    "    return equation\n",
    "\n",
    "T = torch.randn((2,3,4,5,6))\n",
    "eqn = einsum_equation(T)\n",
    "print(f\"equation: {eqn}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HOSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: torch.Size([2, 3, 4, 5])\n",
      "Factor Matrix 1: torch.Size([2, 1])\n",
      "Factor Matrix 2: torch.Size([3, 2])\n",
      "Factor Matrix 3: torch.Size([4, 3])\n",
      "Factor Matrix 4: torch.Size([5, 4])\n",
      "Core Tensor: torch.Size([1, 2, 3, 4])\n",
      "Reconstructed Tensor: torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.randn((2,3,4,5))\n",
    "ranks = [1,2,3,4]\n",
    "print(f\"Original Tensor: {my_tensor.size()}\")\n",
    "\n",
    "# Decompose the tensor into a core tensor and factor matrices\n",
    "A = HOSVD(my_tensor, ranks)\n",
    "A_T = [A[i].T for i in range(len(A))]\n",
    "for i in range(len(A)):\n",
    "    print(f\"Factor Matrix {i+1}: {A[i].size()}\")\n",
    "\n",
    "eqn = einsum_equation(my_tensor)\n",
    "G = torch.einsum(eqn, my_tensor, *A_T)\n",
    "print(f\"Core Tensor: {G.size()}\")\n",
    "\n",
    "# Multiply matrices with core tensor to obtain the original tensor\n",
    "my_tensor_reconstructed = torch.einsum(eqn, G, *A)\n",
    "\n",
    "# Reshape the reconstructed tensor to the original size\n",
    "print(f\"Reconstructed Tensor: {my_tensor_reconstructed.size()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-Order Orthogonal Iteration (HOOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) T: Input tensor of size (s_1,s_2,...,s_N)\n",
    "        2) R: array of decomposition ranks of size N (R_1,R_2,...,R_N)\n",
    "Output: 1) G: core tensor of size (R_1,R_2,...,R_N)\n",
    "        2) A: array of factor matrices of size N (A_1,A_2,...,A_N)\n",
    "\"\"\"\n",
    "def Tucker_ALS(T,R, max_iter=100, tol=1e-20):\n",
    "    # Initialize the factor matrices with HOSVD\n",
    "    A = HOSVD(T, R)\n",
    "    A_T = [A[i].T for i in range(len(A))]\n",
    "\n",
    "    # Iterate until convergence\n",
    "    for iter in range(max_iter):\n",
    "        prev_factors = A.copy()\n",
    "\n",
    "        # Update the factor matrices one by one\n",
    "        for n in range(len(R)):\n",
    "            B = A_T.copy()\n",
    "            B[n] = torch.eye(T.size()[n])\n",
    "            eqn = einsum_equation(T)\n",
    "            Y = torch.einsum(eqn, T, *B)\n",
    "\n",
    "            # Take the leading R[n] columns of the left singular matrix of Yn\n",
    "            Yn = mode_n_matricization(Y, n)\n",
    "            U = torch.svd(Yn).U            \n",
    "            if(R[n] > U.size()[1]):\n",
    "                Zero = torch.zeros(U.size()[0], R[n] - U.size()[1])\n",
    "                An = torch.cat((U, Zero), dim=1)\n",
    "            else:\n",
    "                An = U[:, :R[n]]\n",
    "\n",
    "            # Update the factor matrix\n",
    "            A[n] = An\n",
    "            A_T[n] = An.T\n",
    "\n",
    "        # Check for convergence\n",
    "        if all(torch.norm(A[i] - prev_factors[i]) < tol for i in range(T.dim())):\n",
    "            print(f\"Converged at iteration {iter}\")\n",
    "            break\n",
    "    \n",
    "    # Compute the core tensor after Tucker decomposition\n",
    "    G = torch.einsum(eqn, T, *A_T)\n",
    "\n",
    "    return G, A           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HOOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[[-0.4289, -0.9889,  0.9181,  0.5114,  0.0364, -0.1731],\n",
      "          [-0.9026,  0.5471, -0.4279,  0.0301,  0.5567, -0.8803],\n",
      "          [-0.5848, -0.6082,  0.7001, -1.5437,  0.3230,  0.0702],\n",
      "          [ 0.0175,  0.9655,  1.0856, -0.7991,  0.5537,  0.2649],\n",
      "          [ 0.9500,  0.3290,  3.7842, -0.2163, -0.0925, -1.1061]],\n",
      "\n",
      "         [[-0.4849,  0.0885, -0.3247,  2.2043,  0.6503, -0.4545],\n",
      "          [ 1.2729, -0.0250, -1.2669,  0.1334,  0.1942,  1.3346],\n",
      "          [-0.6313,  1.6723,  0.5130, -2.7286,  1.3269, -0.1290],\n",
      "          [ 0.2781, -0.6621, -1.2806, -1.7114,  0.8791, -1.2371],\n",
      "          [ 1.0276, -0.8481, -1.0582,  2.0718, -1.5551, -0.5539]],\n",
      "\n",
      "         [[ 0.2467, -0.2310,  1.3404, -1.4266,  0.1829, -0.2164],\n",
      "          [-0.6306,  0.6844,  0.5973, -0.6551, -0.4004,  0.7745],\n",
      "          [ 1.6561, -0.1613,  0.6671,  0.2463, -0.9480, -0.7451],\n",
      "          [ 0.2740, -0.4210, -0.1016, -0.1012,  1.1087,  0.9888],\n",
      "          [-1.2599, -0.3694, -1.1233, -0.5488, -0.7771, -0.0852]],\n",
      "\n",
      "         [[-0.4921,  0.8964, -0.3659, -1.1341, -0.8263,  2.0133],\n",
      "          [-1.1333, -1.2965,  0.1318,  2.3442, -0.2600,  0.8287],\n",
      "          [-0.3679,  0.9005, -1.1930,  0.2382,  0.3675,  1.4360],\n",
      "          [-0.3841,  1.2856, -0.8237,  1.2736, -0.4047, -1.9747],\n",
      "          [-1.5091, -0.5033, -0.0969, -0.6446,  1.2050, -0.5095]]],\n",
      "\n",
      "\n",
      "        [[[ 0.8649,  1.7148,  1.1980,  0.9097,  0.6197, -1.0951],\n",
      "          [-0.2389,  0.2609, -0.9425, -0.8411,  0.7766, -1.1889],\n",
      "          [ 0.2303,  0.0683,  0.9754,  1.8345, -0.7673, -0.1393],\n",
      "          [-0.6680,  0.9784,  1.8485, -0.1930, -0.5064,  0.0196],\n",
      "          [ 0.6566, -0.8110, -0.1432, -0.8798,  1.0136, -0.0439]],\n",
      "\n",
      "         [[ 0.2034, -0.0394,  0.6664, -0.4495, -0.8416,  1.1918],\n",
      "          [-1.5573,  0.3233,  0.3981,  0.7421,  0.6267,  0.1861],\n",
      "          [-0.6297, -0.3276,  0.6800, -0.1872,  0.2032,  2.0119],\n",
      "          [ 1.6027, -0.8025, -0.1639,  0.3655,  0.2929, -2.6212],\n",
      "          [ 0.7185,  1.6305, -0.2426,  0.0408,  0.3699,  0.1170]],\n",
      "\n",
      "         [[-0.7913,  1.1727, -1.1511, -0.3965,  0.1820, -0.6676],\n",
      "          [-1.2447,  0.8403,  0.2738,  0.0248,  0.1598, -0.4573],\n",
      "          [ 0.5200, -0.9813, -0.8491, -0.6618,  1.6967, -0.1873],\n",
      "          [-0.3845,  0.1550, -0.0778,  0.1615, -0.7915,  0.7177],\n",
      "          [ 0.0620, -0.5487,  1.8826, -0.1592,  1.3652,  0.3800]],\n",
      "\n",
      "         [[-0.5572, -0.4495,  0.9083, -1.0720, -0.4380,  0.5063],\n",
      "          [ 0.0861,  0.4376, -0.6453, -1.0798, -0.1919, -0.7796],\n",
      "          [-1.4370,  0.0419,  0.8301, -0.2602, -0.6095, -0.2106],\n",
      "          [-0.0760, -0.2840,  0.9776, -0.0942,  1.2061, -0.5631],\n",
      "          [ 1.6524, -0.1977,  0.2931,  0.5954,  2.0148, -0.3814]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1786,  0.8128, -1.6843,  1.0919,  0.4931,  0.5617],\n",
      "          [-0.8295,  0.9936, -1.9264,  0.3515, -1.0519,  1.2279],\n",
      "          [ 0.3646,  0.7227,  1.2619,  0.9961, -2.8419,  1.1096],\n",
      "          [-0.5813,  0.0683, -0.2533,  0.2406,  0.2517, -0.6315],\n",
      "          [-0.3304, -0.9422,  0.5571, -0.6114,  0.3003,  0.3434]],\n",
      "\n",
      "         [[-1.3853, -0.4912, -1.0907, -1.2117, -1.6772, -1.4351],\n",
      "          [-1.1852, -0.4770, -0.8840, -1.5506, -0.0173,  0.3962],\n",
      "          [-0.6862, -0.8794,  1.0558,  0.5991,  0.0430, -0.1304],\n",
      "          [ 1.3852, -1.7226,  0.9478,  0.9393,  0.0315,  0.3415],\n",
      "          [-0.2470,  0.5423, -0.0615, -1.2204,  0.0916, -1.3457]],\n",
      "\n",
      "         [[ 0.7222,  1.1180, -0.9454, -1.7615, -2.4203, -0.8151],\n",
      "          [ 1.0571, -0.2752,  1.2118, -1.0331,  0.2640, -0.4393],\n",
      "          [ 3.1467,  1.4062, -1.7053,  0.5339,  1.9294,  1.9226],\n",
      "          [ 0.4697,  0.8028, -1.0113, -0.8603,  0.9693, -0.5092],\n",
      "          [-1.2667,  1.7478,  1.0976, -0.4430, -1.9742,  1.4812]],\n",
      "\n",
      "         [[-0.0184,  1.1107, -0.4380,  0.7625, -1.0297, -0.4863],\n",
      "          [ 1.6494, -0.2241, -0.4180,  0.5234,  0.5984,  0.9529],\n",
      "          [ 0.0638,  1.2949,  0.7246, -0.2214, -0.7275,  1.0686],\n",
      "          [-0.9339, -0.4787, -1.1249, -1.1861,  1.4427,  1.8939],\n",
      "          [ 0.5287,  1.4244, -0.3515, -0.3175, -1.9706,  1.0805]]]])\n",
      "Tucker Decomposition using TensorLy:\n",
      "Core Tensor Shape: (2, 3, 2, 2)\n",
      "Core Tensor:\n",
      "[[[[-5.1558475   1.2475405 ]\n",
      "   [ 0.83167696 -0.7190757 ]]\n",
      "\n",
      "  [[ 0.69636923  3.8944986 ]\n",
      "   [ 2.4751637   0.5197817 ]]\n",
      "\n",
      "  [[-1.0439463   0.35210794]\n",
      "   [-1.3752477   1.9135059 ]]]\n",
      "\n",
      "\n",
      " [[[ 1.3839549   3.5020263 ]\n",
      "   [ 1.0006055  -0.7054602 ]]\n",
      "\n",
      "  [[-2.0856261   0.38478798]\n",
      "   [-1.1681883   0.36044538]]\n",
      "\n",
      "  [[-1.118142   -0.33341768]\n",
      "   [ 1.1725283   2.3374825 ]]]]\n",
      "Factor Matrix 1 Shape: (3, 2)\n",
      "Factor Matrix 1: \n",
      "[[-0.46027517  0.8768356 ]\n",
      " [ 0.45341218  0.3667373 ]\n",
      " [ 0.76325893  0.31090692]]\n",
      "Factor Matrix 2 Shape: (4, 3)\n",
      "Factor Matrix 2: \n",
      "[[-0.5376632  -0.10371705 -0.54141337]\n",
      " [-0.56214726  0.71282136  0.4193713 ]\n",
      " [ 0.6217009   0.48121     0.01834073]\n",
      " [-0.09163371 -0.49956524  0.72846615]]\n",
      "Factor Matrix 3 Shape: (5, 2)\n",
      "Factor Matrix 3: \n",
      "[[-0.2527394  -0.54999703]\n",
      " [-0.13949734  0.33551612]\n",
      " [ 0.78238416 -0.435323  ]\n",
      " [ 0.29419515  0.61147743]\n",
      " [-0.46689132 -0.14670181]]\n",
      "Factor Matrix 4 Shape: (6, 2)\n",
      "Factor Matrix 4: \n",
      "[[-0.01079884  0.6276406 ]\n",
      " [-0.10416213 -0.33183464]\n",
      " [ 0.39878783 -0.35110635]\n",
      " [ 0.6927883   0.47075143]\n",
      " [-0.5621867   0.38800076]\n",
      " [-0.1843703  -0.02293164]]\n",
      "\n",
      "Norm difference between original tensor and reconstructed tensor: 16.165849685668945\n",
      "\n",
      "Tucker Decomposition using Tucker_ALS:\n",
      "Core tensor Shape: torch.Size([2, 3, 2, 2])\n",
      "Core tensor:\n",
      "tensor([[[[-5.2033, -0.0748],\n",
      "          [-1.0324,  0.0555]],\n",
      "\n",
      "         [[-0.1107, -4.2879],\n",
      "          [ 1.8358,  0.3245]],\n",
      "\n",
      "         [[-0.5901,  0.5583],\n",
      "          [ 2.4281, -1.1228]]],\n",
      "\n",
      "\n",
      "        [[[-0.4062, -3.7190],\n",
      "          [ 1.2029, -0.3227]],\n",
      "\n",
      "         [[-2.1912,  0.4247],\n",
      "          [ 1.3895,  0.0061]],\n",
      "\n",
      "         [[ 1.1813, -0.0326],\n",
      "          [ 0.5920,  2.5192]]]])\n",
      "\n",
      "Factor matrix 1 Shape: torch.Size([3, 2])\n",
      "Factor matrix 1:\n",
      "tensor([[-0.4967, -0.8676],\n",
      "        [ 0.3471, -0.1723],\n",
      "        [ 0.7955, -0.4665]])\n",
      "\n",
      "Factor matrix 2 Shape: torch.Size([4, 3])\n",
      "Factor matrix 2:\n",
      "tensor([[-0.5618,  0.0435, -0.2708],\n",
      "        [-0.5277, -0.7240,  0.3955],\n",
      "        [ 0.6370, -0.5689,  0.0719],\n",
      "        [ 0.0123,  0.3876,  0.8747]])\n",
      "\n",
      "Factor matrix 3 Shape: torch.Size([5, 2])\n",
      "Factor matrix 3:\n",
      "tensor([[-0.3588,  0.4940],\n",
      "        [-0.0895, -0.5363],\n",
      "        [ 0.7457,  0.4829],\n",
      "        [ 0.3275, -0.4465],\n",
      "        [-0.4473,  0.1892]])\n",
      "\n",
      "Factor matrix 4 Shape: torch.Size([6, 2])\n",
      "Factor matrix 4:\n",
      "tensor([[-0.1592,  0.5318],\n",
      "        [-0.0867, -0.3641],\n",
      "        [ 0.4387, -0.1980],\n",
      "        [ 0.5614,  0.6542],\n",
      "        [-0.6386,  0.3398],\n",
      "        [-0.2275,  0.0453]])\n",
      "\n",
      "Norm difference between original tensor and reconstructed tensor: 16.15477752685547\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn((3,4,5,6))\n",
    "ranks=[2, 3, 2, 2]\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "\"\"\"\n",
    "Tucker Decomposition using TensorLy\n",
    "\"\"\"\n",
    "print(\"Tucker Decomposition using TensorLy:\")\n",
    "# Perform Tucker decomposition\n",
    "T = tensor.numpy()\n",
    "core_tensor, factor_matrices =  tl.decomposition.tucker(T, ranks)\n",
    "\n",
    "# Print the shapes of the core tensor and factor matrices\n",
    "print(\"Core Tensor Shape:\", core_tensor.shape)\n",
    "print(\"Core Tensor:\")\n",
    "print(core_tensor)\n",
    "for i in range(len(factor_matrices)):\n",
    "    print(\"Factor Matrix {} Shape: {}\".format(i+1, factor_matrices[i].shape))\n",
    "    print(\"Factor Matrix {}: \".format(i+1))\n",
    "    print(factor_matrices[i])\n",
    "\n",
    "# Norm difference between original tensor and reconstructed tensor\n",
    "print(\"\\nNorm difference between original tensor and reconstructed tensor: {}\".format(tl.norm(T - tl.tucker_to_tensor((core_tensor, factor_matrices)))))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Tucker Decomposition using Tucker_ALS\n",
    "\"\"\"\n",
    "print(\"\\nTucker Decomposition using Tucker_ALS:\")\n",
    "G, A = Tucker_ALS(tensor, ranks)\n",
    "\n",
    "# Print the resulting core tensor and factor matrices\n",
    "print(\"Core tensor Shape:\", G.shape)\n",
    "print('Core tensor:')\n",
    "print(G)\n",
    "for n in range(len(ranks)):\n",
    "    print(\"\\nFactor matrix {} Shape: {}\".format(n+1, A[n].shape))\n",
    "    print(f\"Factor matrix {n+1}:\")\n",
    "    print(A[n])\n",
    "\n",
    "# Norm difference between original tensor and reconstructed tensor\n",
    "eqn = einsum_equation(tensor)\n",
    "print(f\"\\nNorm difference between original tensor and reconstructed tensor: {torch.norm(tensor - torch.einsum(eqn, G, *A))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

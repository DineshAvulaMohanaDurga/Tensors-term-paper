{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tucker Decomposition using ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorly as tl # Used for verification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode-N Matricization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) tensor: Input tensor\n",
    "        2) n: mode along which to matricize the tensor (mode is 0-indexed)\n",
    "Output: matrix: n-mode matricization of the tensor\n",
    "\"\"\"\n",
    "# Take mode = 0 for the first mode, mode = 1 for the second mode, ...., mode = n-1 for nth mode\n",
    "def mode_n_matricization(tensor, n):\n",
    "    mode = n\n",
    "    # Get the size of the original tensor\n",
    "    sz = tensor.size()\n",
    "    # print(f\"tensor size: {sz}\")\n",
    "\n",
    "    # Permute the dimensions of the tensor to bring the chosen mode to the front\n",
    "    # This will make it easy to reshape the tensor into a matrix along the chosen mode\n",
    "    permuted_dimensions = list(range(len(sz)))\n",
    "#     print('Before Permuation, dimensions: ', permuted_dimensions)\n",
    "    permuted_dimensions.remove(mode)\n",
    "    permuted_dimensions.insert(0, mode)\n",
    "#     print('After Permuation, dimensions: ', permuted_dimensions)\n",
    "    permuted_tensor = tensor.permute(*permuted_dimensions)\n",
    "#     print(f\"permuted tensor size: {permuted_tensor.size()}\")\n",
    "\n",
    "    # Reshape the permuted tensor into a matrix along the chosen mode\n",
    "    matrix = permuted_tensor.reshape(sz[mode], -1)\n",
    "#     print(f\"matrix size: {matrix.size()}\")\n",
    "\n",
    "#     print(f\"n-mode matricization along mode {mode}:\")\n",
    "#     print(matrix)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Mode-N Matricization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: torch.Size([2, 3, 4])\n",
      "\n",
      "n-mode matricization along mode 0:\n",
      "tensor([[ 1.,  4.,  7., 10.,  2.,  5.,  8., 11.,  3.,  6.,  9., 12.],\n",
      "        [13., 16., 19., 22., 14., 17., 20., 23., 15., 18., 21., 24.]])\n",
      "\n",
      "n-mode matricization along mode 1:\n",
      "tensor([[ 1.,  4.,  7., 10., 13., 16., 19., 22.],\n",
      "        [ 2.,  5.,  8., 11., 14., 17., 20., 23.],\n",
      "        [ 3.,  6.,  9., 12., 15., 18., 21., 24.]])\n",
      "\n",
      "n-mode matricization along mode 2:\n",
      "tensor([[ 1.,  2.,  3., 13., 14., 15.],\n",
      "        [ 4.,  5.,  6., 16., 17., 18.],\n",
      "        [ 7.,  8.,  9., 19., 20., 21.],\n",
      "        [10., 11., 12., 22., 23., 24.]])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.empty((2,3,4))\n",
    "my_tensor[0, :, :] = torch.tensor([[1,4,7,10], [2,5,8,11], [3,6,9,12]])\n",
    "my_tensor[1, :, :] = torch.tensor([[13,16,19,22], [14,17,20,23], [15,18,21,24]])\n",
    "print(f\"Original Tensor: {my_tensor.size()}\")\n",
    "\n",
    "for n in range(len(my_tensor.size())):\n",
    "    print(f\"\\nn-mode matricization along mode {n}:\")\n",
    "    matrix = mode_n_matricization(my_tensor, n)\n",
    "    print(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher Order Singular Value Decomposition (HOSVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) X: Input tensor of size (s_1,s_2,...,s_N)\n",
    "        2) R: array of decomposition ranks of size N (R_1,R_2,...,R_N)\n",
    "Output: A: array of factor matrices of size N (A_1,A_2,...,A_N)\n",
    "\"\"\"\n",
    "def HOSVD(X, R):\n",
    "    N = len(R)\n",
    "    A = []\n",
    "    for n in range(N):\n",
    "        # Matricize the input tensor along the n-th mode\n",
    "        Xn = mode_n_matricization(X, n)\n",
    "        # Compute the left singular matrix of the n-th matricization\n",
    "        U = torch.svd(Xn).U\n",
    "        # Take the leading R[n] columns of the left singular matrix\n",
    "        if(R[n] > U.size()[1]):\n",
    "            Zero = torch.zeros(U.size()[0], R[n] - U.size()[1])\n",
    "            An = torch.cat((U, Zero), dim=1)\n",
    "        else:\n",
    "            An = U[:, :R[n]]\n",
    "        A.append(An)\n",
    "    return A  \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einsum functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equation: abcde,za,yb,xc,wd,ve->zyxwv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Input: T: Input tensor\n",
    "Output: equation: equation string for torch.einsum()\n",
    "\"\"\"\n",
    "def einsum_equation(T):\n",
    "    equation = ''\n",
    "    for i in range(len(T.size())): \n",
    "        equation += f'{chr(97 + i)}'\n",
    "    for i in range(len(T.size())):\n",
    "        equation += f',{chr(122 -i)}{chr(97 + i)}'\n",
    "    equation += '->'\n",
    "    for i in range(len(T.size())):\n",
    "        equation += f'{chr(122 - i)}'\n",
    "    # print(f\"equation: {equation}\")\n",
    "    return equation\n",
    "\n",
    "T = torch.randn((2,3,4,5,6))\n",
    "eqn = einsum_equation(T)\n",
    "print(f\"equation: {eqn}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HOSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tensor: torch.Size([2, 3, 4, 5])\n",
      "Factor Matrix 1: torch.Size([2, 1])\n",
      "Factor Matrix 2: torch.Size([3, 2])\n",
      "Factor Matrix 3: torch.Size([4, 3])\n",
      "Factor Matrix 4: torch.Size([5, 4])\n",
      "Core Tensor: torch.Size([1, 2, 3, 4])\n",
      "Reconstructed Tensor: torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "my_tensor = torch.randn((2,3,4,5))\n",
    "ranks = [1,2,3,4]\n",
    "print(f\"Original Tensor: {my_tensor.size()}\")\n",
    "\n",
    "# Decompose the tensor into a core tensor and factor matrices\n",
    "A = HOSVD(my_tensor, ranks)\n",
    "A_T = [A[i].T for i in range(len(A))]\n",
    "for i in range(len(A)):\n",
    "    print(f\"Factor Matrix {i+1}: {A[i].size()}\")\n",
    "\n",
    "eqn = einsum_equation(my_tensor)\n",
    "G = torch.einsum(eqn, my_tensor, *A_T)\n",
    "print(f\"Core Tensor: {G.size()}\")\n",
    "\n",
    "# Multiply matrices with core tensor to obtain the original tensor\n",
    "my_tensor_reconstructed = torch.einsum(eqn, G, *A)\n",
    "\n",
    "# Reshape the reconstructed tensor to the original size\n",
    "print(f\"Reconstructed Tensor: {my_tensor_reconstructed.size()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Higher-Order Orthogonal Iteration (HOOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) T: Input tensor of size (s_1,s_2,...,s_N)\n",
    "        2) R: array of decomposition ranks of size N (R_1,R_2,...,R_N)\n",
    "Output: 1) G: core tensor of size (R_1,R_2,...,R_N)\n",
    "        2) A: array of factor matrices of size N (A_1,A_2,...,A_N)\n",
    "\"\"\"\n",
    "def Tucker_ALS(T,R, max_iter=100, tol=1e-20):\n",
    "    # Initialize the factor matrices with HOSVD\n",
    "    A = HOSVD(T, R)\n",
    "    A_T = [A[i].T for i in range(len(A))]\n",
    "\n",
    "    # Iterate until convergence\n",
    "    for iter in range(max_iter):\n",
    "        prev_factors = A.copy()\n",
    "\n",
    "        # Update the factor matrices one by one\n",
    "        for n in range(len(R)):\n",
    "            B = A_T.copy()\n",
    "            B[n] = torch.eye(T.size()[n])\n",
    "            eqn = einsum_equation(T)\n",
    "            Y = torch.einsum(eqn, T, *B)\n",
    "\n",
    "            # Take the leading R[n] columns of the left singular matrix of Yn\n",
    "            Yn = mode_n_matricization(Y, n)\n",
    "            U = torch.svd(Yn).U            \n",
    "            if(R[n] > U.size()[1]):\n",
    "                Zero = torch.zeros(U.size()[0], R[n] - U.size()[1])\n",
    "                An = torch.cat((U, Zero), dim=1)\n",
    "            else:\n",
    "                An = U[:, :R[n]]\n",
    "\n",
    "            # Update the factor matrix\n",
    "            A[n] = An\n",
    "            A_T[n] = An.T\n",
    "\n",
    "        # Check for convergence\n",
    "        if all(torch.norm(A[i] - prev_factors[i]) < tol for i in range(T.dim())):\n",
    "            print(f\"Converged at iteration {iter}\")\n",
    "            break\n",
    "    \n",
    "    # Compute the core tensor after Tucker decomposition\n",
    "    G = torch.einsum(eqn, T, *A_T)\n",
    "\n",
    "    return G, A           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test HOOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      "tensor([[[[ 1.2242e-01, -8.4382e-01, -8.2342e-01,  1.1663e+00,  8.7270e-01,\n",
      "           -9.7322e-02],\n",
      "          [-1.2077e+00,  7.6333e-01,  3.3325e-01, -1.5215e+00,  6.1579e-01,\n",
      "           -2.0557e+00],\n",
      "          [-5.8748e-02, -2.1565e+00,  3.3193e-01,  1.1350e+00,  5.3331e-01,\n",
      "           -6.3837e-01],\n",
      "          [ 2.2478e+00,  8.1522e-01, -8.9626e-01,  1.7559e+00, -5.0071e-02,\n",
      "            8.0354e-01],\n",
      "          [ 5.8242e-03,  9.6987e-01, -1.8058e+00,  2.2577e+00,  3.9107e-01,\n",
      "            1.9515e+00]],\n",
      "\n",
      "         [[ 1.5516e+00, -9.2935e-01, -8.6245e-01, -1.0877e+00, -8.2818e-01,\n",
      "           -4.8429e-01],\n",
      "          [ 3.8183e-01,  6.8823e-01, -1.1482e+00,  1.9867e-01, -7.4671e-01,\n",
      "           -8.2537e-02],\n",
      "          [-3.0099e-01,  7.3862e-01, -9.2280e-02, -1.8697e+00, -7.2662e-01,\n",
      "            2.7317e-03],\n",
      "          [-7.1189e-01,  2.2296e-01, -6.0592e-01, -2.1110e+00,  4.5264e-01,\n",
      "           -1.7107e-01],\n",
      "          [ 3.5410e-01, -1.7480e-01,  7.3182e-03, -4.0453e-01,  2.0798e+00,\n",
      "            1.7412e+00]],\n",
      "\n",
      "         [[-2.2846e-02,  3.5259e-01, -5.4155e-01,  1.6604e+00, -6.8174e-01,\n",
      "            6.9722e-01],\n",
      "          [ 3.9187e-01,  3.2001e-01,  1.7848e+00,  3.2412e+00, -2.0077e-01,\n",
      "           -1.1545e+00],\n",
      "          [ 8.5064e-01, -2.4114e-01,  1.8815e-01, -2.1015e-01, -3.1599e-01,\n",
      "           -7.5219e-02],\n",
      "          [-4.7674e-01,  7.5949e-02,  9.9435e-01,  2.3707e-01, -1.5422e+00,\n",
      "            7.5173e-01],\n",
      "          [-1.1260e+00, -3.2384e-01,  7.1871e-01,  7.4578e-01,  1.4297e+00,\n",
      "           -1.5052e-01]],\n",
      "\n",
      "         [[-3.0161e-01,  8.5209e-01, -5.9453e-01, -1.1023e+00,  1.2155e-01,\n",
      "            1.3769e+00],\n",
      "          [ 1.2436e+00,  4.4098e-02, -1.4629e-01, -3.9753e-01, -1.3323e+00,\n",
      "           -3.4199e-01],\n",
      "          [ 8.0567e-01, -1.5449e-01, -8.0438e-01,  5.6037e-01, -2.0196e-02,\n",
      "           -7.8206e-01],\n",
      "          [ 5.1871e-01, -1.3758e+00,  7.7417e-02,  2.0060e+00, -3.6577e-04,\n",
      "           -1.4855e+00],\n",
      "          [-1.5552e+00,  7.5859e-01,  7.7243e-01,  5.0527e-01, -1.0508e+00,\n",
      "           -1.0661e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9201e-01,  4.2109e-01, -8.1540e-01, -1.7520e-01, -6.8913e-01,\n",
      "           -9.0734e-02],\n",
      "          [ 1.2139e+00,  6.9044e-01, -3.7033e-01, -1.6683e+00,  1.3436e+00,\n",
      "           -2.1516e+00],\n",
      "          [ 4.4334e-01,  3.6427e-01,  8.6396e-01, -5.9760e-01, -1.1921e+00,\n",
      "            3.2591e-01],\n",
      "          [-2.0675e-01, -6.7098e-01,  1.4005e+00, -5.8069e-01,  1.6456e+00,\n",
      "            7.7081e-01],\n",
      "          [ 1.2585e-01, -9.1129e-01,  3.8552e-02,  1.2076e+00,  1.1516e+00,\n",
      "           -7.4119e-01]],\n",
      "\n",
      "         [[-3.5647e-01,  5.7715e-01,  1.6505e+00,  1.8720e-01,  1.9064e+00,\n",
      "            9.8028e-01],\n",
      "          [-5.8113e-01,  3.0370e-01, -8.2029e-01, -1.2013e+00,  4.3618e-01,\n",
      "           -3.1787e-01],\n",
      "          [ 1.3736e+00,  4.5184e-01,  7.9889e-01,  1.8746e+00, -4.4763e-01,\n",
      "            2.4195e-01],\n",
      "          [-8.3658e-01,  9.2690e-01,  1.1280e+00,  2.0145e+00, -2.3228e-01,\n",
      "           -3.6961e-01],\n",
      "          [ 5.7695e-01,  2.7598e-01, -4.6049e-01, -6.1668e-01, -1.0449e+00,\n",
      "            7.2859e-01]],\n",
      "\n",
      "         [[-3.5750e-01,  1.7081e+00, -2.0540e-01,  6.9417e-01,  9.1876e-01,\n",
      "            1.7794e+00],\n",
      "          [-1.9146e+00, -1.2588e+00,  3.7602e-01,  8.6837e-01,  7.9464e-01,\n",
      "            6.5807e-01],\n",
      "          [-1.1991e+00,  1.5284e+00, -8.8148e-01, -2.1047e-01, -1.0283e+00,\n",
      "           -1.6402e+00],\n",
      "          [-4.5479e-01,  6.9157e-02,  7.9259e-01,  1.1618e+00, -3.0558e+00,\n",
      "            6.9193e-02],\n",
      "          [-2.0597e-01,  1.1132e+00,  6.5267e-01, -2.2171e+00,  1.0261e+00,\n",
      "           -2.8654e-01]],\n",
      "\n",
      "         [[-8.2936e-01,  7.0860e-01, -2.8079e-01,  6.8556e-01,  5.5615e-01,\n",
      "           -1.2267e-01],\n",
      "          [ 6.5582e-01, -6.8623e-01, -1.2891e+00,  3.2034e-01,  2.1375e-01,\n",
      "            6.5971e-01],\n",
      "          [-1.3132e+00, -6.7551e-01, -4.0719e-01, -1.8141e+00, -1.0269e+00,\n",
      "            3.1040e+00],\n",
      "          [ 3.2413e-01, -1.0114e+00,  1.2322e+00, -6.7718e-01,  1.2385e+00,\n",
      "            3.2275e-01],\n",
      "          [ 3.2799e-01,  9.3600e-01,  2.4344e+00, -3.8165e-01, -9.4988e-01,\n",
      "            4.3379e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9710e-02,  2.0084e+00,  7.8442e-01,  5.6664e-01, -1.1775e-01,\n",
      "            1.2401e-01],\n",
      "          [-1.4803e+00,  1.1727e+00,  6.7725e-01,  7.9642e-02, -1.8821e-02,\n",
      "            8.9579e-01],\n",
      "          [ 1.3925e+00,  2.9801e+00,  3.8991e-01, -9.9317e-01, -6.8266e-01,\n",
      "            8.0791e-01],\n",
      "          [-6.3657e-01,  3.6370e-01,  8.5087e-03,  5.1341e-01,  1.6998e-01,\n",
      "           -1.9471e+00],\n",
      "          [-1.4186e+00, -1.0815e+00, -8.9854e-01,  1.0846e+00,  2.9754e-01,\n",
      "            6.9728e-01]],\n",
      "\n",
      "         [[-8.6230e-01, -6.9380e-01, -3.8120e-01, -1.5464e-01,  2.7483e-01,\n",
      "            6.3174e-01],\n",
      "          [-5.7000e-01, -1.5993e+00,  2.6677e-01, -7.3070e-01,  9.7585e-01,\n",
      "            9.4501e-01],\n",
      "          [ 1.4996e-03,  6.7817e-01,  8.4820e-01, -2.0782e-01,  1.7769e+00,\n",
      "           -7.0011e-01],\n",
      "          [-1.0103e+00,  7.3752e-01,  8.3027e-01,  3.1752e-01,  2.6313e-01,\n",
      "            6.5237e-01],\n",
      "          [-3.1637e-01, -3.2700e-01, -4.0129e-01, -4.8862e-01,  1.6339e+00,\n",
      "            1.2866e+00]],\n",
      "\n",
      "         [[-2.6556e-01,  7.6162e-02, -9.9150e-01, -1.4317e-01,  3.4036e-01,\n",
      "            1.7500e-01],\n",
      "          [-5.0208e-01, -7.8661e-01,  1.9784e+00,  5.2774e-01, -9.8903e-01,\n",
      "            6.4592e-01],\n",
      "          [-1.0676e+00, -3.8641e-01,  6.9906e-01,  1.4918e-01, -2.1231e+00,\n",
      "            7.3434e-01],\n",
      "          [-4.5448e-01,  8.1566e-01, -1.5050e+00,  2.6331e+00,  1.8060e+00,\n",
      "            1.0794e+00],\n",
      "          [ 3.2826e-01,  5.5372e-01, -6.9904e-01,  2.1188e-02, -6.6837e-01,\n",
      "           -5.9017e-01]],\n",
      "\n",
      "         [[-3.3934e-01, -7.3259e-01,  1.7844e-01,  5.7932e-01,  2.3044e-01,\n",
      "           -2.5207e-01],\n",
      "          [ 4.0416e-01,  7.9744e-01, -1.4032e+00, -2.8271e-01, -1.5619e+00,\n",
      "            5.2596e-01],\n",
      "          [-1.7691e-01,  4.8183e-01, -1.0948e+00,  1.8258e+00,  7.6939e-02,\n",
      "           -2.9764e-01],\n",
      "          [ 1.1223e+00,  2.4456e-01,  1.0354e+00,  8.2271e-02,  1.5820e+00,\n",
      "           -5.1414e-01],\n",
      "          [-1.7998e+00, -5.0714e-01,  1.4992e+00,  2.8563e+00, -7.8120e-01,\n",
      "            2.2195e+00]]]])\n",
      "Tucker Decomposition using TensorLy:\n",
      "Core Tensor Shape: (2, 3, 2, 2)\n",
      "Core Tensor:\n",
      "[[[[ 2.190528   -3.473734  ]\n",
      "   [-3.2120817  -0.83664066]]\n",
      "\n",
      "  [[ 2.8224416   0.94030374]\n",
      "   [ 0.4875372  -0.49145538]]\n",
      "\n",
      "  [[ 0.4071278  -1.159634  ]\n",
      "   [-0.01754589  1.809964  ]]]\n",
      "\n",
      "\n",
      " [[[-3.8741717  -0.8037992 ]\n",
      "   [-1.3387897   2.7609491 ]]\n",
      "\n",
      "  [[ 0.36313963  1.1565977 ]\n",
      "   [ 2.195933    1.3396785 ]]\n",
      "\n",
      "  [[ 1.201051    0.22788899]\n",
      "   [-0.09020365  0.46341988]]]]\n",
      "Factor Matrix 1 Shape: (3, 2)\n",
      "Factor Matrix 1: \n",
      "[[-0.1271305   0.9654943 ]\n",
      " [ 0.97141427  0.1675085 ]\n",
      " [ 0.20047984 -0.19940348]]\n",
      "Factor Matrix 2 Shape: (4, 3)\n",
      "Factor Matrix 2: \n",
      "[[-0.46182594  0.41886917  0.7026385 ]\n",
      " [ 0.5058872   0.8268506  -0.21684486]\n",
      " [ 0.6811204  -0.36433744  0.442644  ]\n",
      " [-0.25859228 -0.09013867 -0.5131703 ]]\n",
      "Factor Matrix 3 Shape: (5, 2)\n",
      "Factor Matrix 3: \n",
      "[[-0.09859256 -0.3699396 ]\n",
      " [-0.59515864 -0.42323187]\n",
      " [ 0.46389467 -0.33095032]\n",
      " [ 0.6369815  -0.34224117]\n",
      " [ 0.12297163  0.6762857 ]]\n",
      "Factor Matrix 4 Shape: (6, 2)\n",
      "Factor Matrix 4: \n",
      "[[ 0.08665968 -0.1138587 ]\n",
      " [ 0.05491792 -0.46714708]\n",
      " [ 0.08715677  0.17375043]\n",
      " [ 0.96957135  0.05652155]\n",
      " [-0.13508785  0.74245965]\n",
      " [ 0.15349416  0.42916146]]\n",
      "\n",
      "Norm difference between original tensor and reconstructed tensor: 17.20798110961914\n",
      "\n",
      "Tucker Decomposition using Tucker_ALS:\n",
      "Core tensor Shape: torch.Size([2, 3, 2, 2])\n",
      "Core tensor:\n",
      "tensor([[[[-4.4335, -0.3491],\n",
      "          [ 0.0534, -2.0336]],\n",
      "\n",
      "         [[ 1.2087, -2.2253],\n",
      "          [ 2.1033, -2.2055]],\n",
      "\n",
      "         [[ 1.8403, -0.4951],\n",
      "          [-0.4068, -1.1924]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5537,  2.1306],\n",
      "          [-2.5866, -2.2860]],\n",
      "\n",
      "         [[ 1.5913, -0.8463],\n",
      "          [ 1.7597, -0.9953]],\n",
      "\n",
      "         [[-1.2537,  2.1031],\n",
      "          [-1.1086, -0.6282]]]])\n",
      "\n",
      "Factor matrix 1 Shape: torch.Size([3, 2])\n",
      "Factor matrix 1:\n",
      "tensor([[ 0.9740, -0.0394],\n",
      "        [ 0.0464,  0.9986],\n",
      "        [ 0.2219, -0.0359]])\n",
      "\n",
      "Factor matrix 2 Shape: torch.Size([4, 3])\n",
      "Factor matrix 2:\n",
      "tensor([[ 0.3793, -0.8099, -0.4435],\n",
      "        [-0.6349, -0.2731,  0.0530],\n",
      "        [-0.4036,  0.2646, -0.8544],\n",
      "        [ 0.5387,  0.4467, -0.2654]])\n",
      "\n",
      "Factor matrix 3 Shape: torch.Size([5, 2])\n",
      "Factor matrix 3:\n",
      "tensor([[ 0.0607, -0.1817],\n",
      "        [ 0.3223,  0.3429],\n",
      "        [-0.5039,  0.3310],\n",
      "        [-0.6559,  0.4198],\n",
      "        [-0.4564, -0.7508]])\n",
      "\n",
      "Factor matrix 4 Shape: torch.Size([6, 2])\n",
      "Factor matrix 4:\n",
      "tensor([[ 0.1935, -0.2692],\n",
      "        [-0.1201,  0.3318],\n",
      "        [-0.2234,  0.3641],\n",
      "        [ 0.9305,  0.0356],\n",
      "        [-0.1649, -0.6006],\n",
      "        [-0.0724, -0.5682]])\n",
      "\n",
      "Norm difference between original tensor and reconstructed tensor: 17.035856246948242\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randn((3,4,5,6))\n",
    "ranks=[2, 3, 2, 2]\n",
    "print(\"Original tensor:\")\n",
    "print(tensor)\n",
    "\n",
    "\"\"\"\n",
    "Tucker Decomposition using TensorLy\n",
    "\"\"\"\n",
    "print(\"Tucker Decomposition using TensorLy:\")\n",
    "# Perform Tucker decomposition\n",
    "T = tensor.numpy()\n",
    "core_tensor, factor_matrices =  tl.decomposition.tucker(T, ranks)\n",
    "\n",
    "# Print the shapes of the core tensor and factor matrices\n",
    "print(\"Core Tensor Shape:\", core_tensor.shape)\n",
    "print(\"Core Tensor:\")\n",
    "print(core_tensor)\n",
    "for i in range(len(factor_matrices)):\n",
    "    print(\"Factor Matrix {} Shape: {}\".format(i+1, factor_matrices[i].shape))\n",
    "    print(\"Factor Matrix {}: \".format(i+1))\n",
    "    print(factor_matrices[i])\n",
    "\n",
    "# Norm difference between original tensor and reconstructed tensor\n",
    "print(\"\\nNorm difference between original tensor and reconstructed tensor: {}\".format(tl.norm(T - tl.tucker_to_tensor((core_tensor, factor_matrices)))))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Tucker Decomposition using Tucker_ALS\n",
    "\"\"\"\n",
    "print(\"\\nTucker Decomposition using Tucker_ALS:\")\n",
    "G, A = Tucker_ALS(tensor, ranks)\n",
    "\n",
    "# Print the resulting core tensor and factor matrices\n",
    "print(\"Core tensor Shape:\", G.shape)\n",
    "print('Core tensor:')\n",
    "print(G)\n",
    "for n in range(len(ranks)):\n",
    "    print(\"\\nFactor matrix {} Shape: {}\".format(n+1, A[n].shape))\n",
    "    print(f\"Factor matrix {n+1}:\")\n",
    "    print(A[n])\n",
    "\n",
    "# Norm difference between original tensor and reconstructed tensor\n",
    "eqn = einsum_equation(tensor)\n",
    "print(f\"\\nNorm difference between original tensor and reconstructed tensor: {torch.norm(tensor - torch.einsum(eqn, G, *A))}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_count_sketch(m,n):\n",
    "    hash=np.random.randint(100,1000)\n",
    "    # hash=rand.randint(100,1000)\n",
    "    # hash*i mod m\n",
    "    omega = np.zeros((m,n))\n",
    "    for i in range(n):\n",
    "        pos = np.mod(hash*i,m)\n",
    "        omega[pos,i]=1\n",
    "    D = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        D[i,i]=np.random.choice([-1,1])\n",
    "    # print(omega)\n",
    "    return omega @ D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_composite_sketching_mat(s,R,epsilon):\n",
    "    k1 = int(3*(R/epsilon))\n",
    "    k2 = int(3*(R*R + R/epsilon))\n",
    "    T = gen_count_sketch(s,k2)\n",
    "    G= np.random.randn(k2,k1)*(1/np.sqrt(k1))\n",
    "    S = T @ G\n",
    "    # print(np.shape(T))\n",
    "    # print(np.shape(G))\n",
    "    return S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Init_RRF(M,R,epsilon):\n",
    "    m =np.shape(M)[1]\n",
    "    S=gen_composite_sketching_mat(m,R,epsilon)\n",
    "    B = M @ S\n",
    "    U,sigma,V = np.linalg.svd(B)\n",
    "    print(np.shape(U))\n",
    "    return U[:,:R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) tensor: Input tensor\n",
    "        2) n: mode along which to matricize the tensor (mode is 0-indexed)\n",
    "Output: matrix: n-mode matricization of the tensor\n",
    "\"\"\"\n",
    "# Take mode = 0 for the first mode, mode = 1 for the second mode, ...., mode = n-1 for nth mode\n",
    "def mode_n_matricization(tensor, n):\n",
    "    mode = n\n",
    "    # Get the size of the original tensor\n",
    "    sz = tensor.size()\n",
    "    # print(f\"tensor size: {sz}\")\n",
    "\n",
    "    # Permute the dimensions of the tensor to bring the chosen mode to the front\n",
    "    # This will make it easy to reshape the tensor into a matrix along the chosen mode\n",
    "    permuted_dimensions = list(range(len(sz)))\n",
    "#     print('Before Permuation, dimensions: ', permuted_dimensions)\n",
    "    permuted_dimensions.remove(mode)\n",
    "    permuted_dimensions.insert(0, mode)\n",
    "#     print('After Permuation, dimensions: ', permuted_dimensions)\n",
    "    permuted_tensor = tensor.permute(*permuted_dimensions)\n",
    "#     print(f\"permuted tensor size: {permuted_tensor.size()}\")\n",
    "\n",
    "    # Reshape the permuted tensor into a matrix along the chosen mode\n",
    "    matrix = permuted_tensor.reshape(sz[mode], -1)\n",
    "#     print(f\"matrix size: {matrix.size()}\")\n",
    "\n",
    "#     print(f\"n-mode matricization along mode {mode}:\")\n",
    "#     print(matrix)\n",
    "\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSVD_LRLS(Z, Y, R):\n",
    "\n",
    "    m,s = Y.shape\n",
    "\n",
    "    S = np.random.randn(s, 5*R)\n",
    "    B = np.linalg.inv((Z.T @ Z))\n",
    "    C= B @ Z.T @  Y @ S\n",
    "\n",
    "    Q, r = np.linalg.qr(C)\n",
    "\n",
    "    D = Q.T @ B @ Z.T @ Y\n",
    "\n",
    "    U, sig , V = np.linalg.svd(D)\n",
    "\n",
    "    sig = np.diag(sig)\n",
    "\n",
    "    print(U.shape)\n",
    "    print(sig.shape)\n",
    "    print(V.shape)\n",
    "\n",
    "    return Q @ U[:, :R] @ sig[:R, :R] , V[:, :R]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 8)\n",
      "(5, 5)\n",
      "(5, 5)\n",
      "(8, 5)\n",
      "(5, 5)\n"
     ]
    }
   ],
   "source": [
    "# Testing RSVD-LRLS\n",
    "\n",
    "m = 10\n",
    "s = 5 \n",
    "r = 8\n",
    "R = 5\n",
    "\n",
    "Z = np.random.randn(m, r)\n",
    "Y = np.random.randn(m, s)\n",
    "\n",
    "C , A = RSVD_LRLS(Z,Y,R)\n",
    "\n",
    "print(C.shape)\n",
    "print(A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tensor_sketch(m,sn):\n",
    "    hash1 = np.random.randint(100,1000)\n",
    "    hash2 = np.random.randint(100,1000)\n",
    "    hash3 = np.random.randint(100,1000)\n",
    "    hash4 = np.random.randint(100,1000)\n",
    "\n",
    "    omega = np.zeros((m,sn))\n",
    "    for i in range(sn):\n",
    "        pos = np.mod(hash1 * (i **3) + hash2 * (i ** 2) + hash3 * (i) ,m)    # 3 wise independent hashes\n",
    "        omega[pos,i]=1\n",
    "    D = np.zeros((sn,sn))\n",
    "    for i in range(sn):\n",
    "        hash = np.mod(hash4 * (i **4) + hash1 * (i **3) + hash2 * (i ** 2) + hash3 * (i) ,2)   # 4 wise independent hashes\n",
    "        D[i,i] = -1 if hash == 0 else 1\n",
    "    return omega @ D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sketch_Tucker_ALS(T, ranks, Imax, epsilon):\n",
    "\n",
    "    N = len(ranks)\n",
    "    C = np.zeros(ranks)\n",
    "\n",
    "    A = [None]\n",
    "    for n in range(1, N):\n",
    "        T_tensor = torch.Tensor(T)\n",
    "        A.append(Init_RRF(mode_n_matricization(T_tensor, n).numpy(), ranks[n], epsilon))\n",
    "\n",
    "    \n",
    "    for i in range(Imax):\n",
    "        for n in range(N):\n",
    "            # Build sketching S\n",
    "            shape = T.shape\n",
    "            shp = 1\n",
    "            for s in range(len(shape)):\n",
    "                if s != n :\n",
    "                    shp = shp * shape[s]\n",
    "\n",
    "            Sn = gen_tensor_sketch(m, shp)\n",
    "            T_tensor = torch.Tensor(T)\n",
    "            Y = Sn @ (mode_n_matricization(T_tensor, n).numpy()).T\n",
    "\n",
    "            if n == 0:\n",
    "                A_kronecker = A[1]\n",
    "                for j in range(2, N):\n",
    "                    if j != n:\n",
    "                        A_kronecker = np.kron(A_kronecker, A[j])\n",
    "            else:\n",
    "                A_kronecker = A[0]\n",
    "                for j in range(1, N):\n",
    "                    if j != n:\n",
    "                        A_kronecker = np.kron(A_kronecker, A[j])\n",
    "            \n",
    "            print(f'n = {n} and Sn = {Sn.shape}')\n",
    "            print(f'n = {n} and Akron = {A_kronecker.shape}')\n",
    "\n",
    "            Z = Sn @ A_kronecker\n",
    "            C_matrix, A[n] = RSVD_LRLS(Z, Y, ranks[n]) \n",
    "\n",
    "            C = mode_n_matricization( torch.Tensor(C), n).numpy()\n",
    "            C = C_matrix.T\n",
    "            C = C.reshape(ranks)\n",
    "\n",
    "        return (C, A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Testing Sketch Tucker\n",
    "#  Error prone code since matrices are random\n",
    "# tensor = np.random.randn(10,10,10)\n",
    "# ranks = (5,5,5)\n",
    "# imax = 5\n",
    "# eps = 0.1\n",
    "\n",
    "# Sketch_Tucker_ALS(tensor, ranks, imax, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input: A: Array of matrices whose Khatri-Rao product is to be calculated\n",
    "Output: B: Khatri-Rao product of the matrices in A\n",
    "\"\"\"\n",
    "def khatri_rao_product(A):\n",
    "    N = len(A)\n",
    "    num_cols = A[0].shape[1]\n",
    "    x_dim = 1\n",
    "    for i in range(N):\n",
    "        x_dim *= A[i].shape[0]\n",
    "    B = torch.empty((x_dim, num_cols))\n",
    "\n",
    "    for i in range(num_cols):\n",
    "        for j in range(N):\n",
    "            if j == 0:\n",
    "                kron_prod = A[j][:, i]\n",
    "            else:\n",
    "                kron_prod = torch.kron(kron_prod, A[j][:, i])\n",
    "        B[:, i] = kron_prod\n",
    "\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Input:  1) T: Tensor of size (s_1, s_2, ..., s_N)\n",
    "        2) R: CP-Rank of the Tensor\n",
    "Output: 1) A: Array of N factor matrices of size (s_i, R)\n",
    "\"\"\"\n",
    "def CP_ALS(T, R, max_iter=100, tol=1e-5):\n",
    "    N = len(T.shape)\n",
    "    sz = T.shape\n",
    "    A = []\n",
    "    for n in range(N):\n",
    "        An = torch.rand(sz[n], R)\n",
    "        A.append(An)\n",
    "\n",
    "    # Iterate until convergence\n",
    "    for iter in range(max_iter):\n",
    "        prev_factors = A.copy()\n",
    "\n",
    "        for n in range(N):\n",
    "            # Calculate the Khatri-Rao product of all the factor matrices except the n-th factor matrix\n",
    "            B = khatri_rao_product(A[:n] + A[n+1:])\n",
    "            B_pinv = torch.pinverse(B)\n",
    "\n",
    "            # Calculate the n-mode matricization of the tensor\n",
    "            Tn = mode_n_matricization(T, n)\n",
    "            \n",
    "            # Calculate the n-th factor matrix\n",
    "            AnT = torch.mm(B_pinv, Tn.T)\n",
    "            A[n] = AnT.T\n",
    "\n",
    "        # Check for convergence\n",
    "        if all(torch.norm(A[i] - prev_factors[i]) < tol for i in range(T.dim())):\n",
    "            print(f\"Converged at iteration {iter}\")\n",
    "            break\n",
    "\n",
    "    return A  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CP_Sketch_Tucker(T, R, Imax, epsilon):\n",
    "\n",
    "    N = T.ndim\n",
    "    ranks = tuple([R] * N)\n",
    "    C, B = Sketch_Tucker_ALS(T, ranks, Imax, epsilon)\n",
    "    A = CP_ALS(C, R)\n",
    "    result = []\n",
    "\n",
    "    for i in range(len(A)):\n",
    "        result.append(B[i] @ A[i])\n",
    "\n",
    "    return result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
